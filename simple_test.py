"""
ç®€å•çš„ Lucky Vicky æµ‹è¯•
ä½¿ç”¨æ‚¨çš„ Token
"""

from huggingface_hub import InferenceClient
import os

# æ‚¨çš„ Token (è¯·ä»ç¯å¢ƒå˜é‡æˆ– .env æ–‡ä»¶è¯»å–)
TOKEN = os.getenv('HF_TOKEN', 'your_huggingface_token_here')

print("ğŸ¤— å¼€å§‹æµ‹è¯• Hugging Face API\n")

try:
    # åˆ›å»ºå®¢æˆ·ç«¯
    client = InferenceClient(token=TOKEN)
    print("âœ… å®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ")
    
    # æµ‹è¯•ç®€å•å¯¹è¯
    print("\næ­£åœ¨æµ‹è¯• API...")
    messages = [{"role": "user", "content": "Hi"}]
    
    response = client.chat_completion(
        messages=messages,
        model="Qwen/Qwen2.5-1.5B-Instruct",
        max_tokens=50
    )
    
    print(f"âœ… API å“åº”æˆåŠŸ!")
    print(f"å›å¤: {response.choices[0].message.content}")
    
    # æµ‹è¯• Lucky Vicky
    print("\n" + "="*60)
    print("æµ‹è¯• Lucky Vicky ç”Ÿæˆå™¨")
    print("="*60)
    
    system = """è«‹ç”¨å°ç£ç¿’æ…£çš„ä¸­æ–‡ä¾†å¯«é€™æ®µ po æ–‡:
è«‹ç”¨å“¡ç‘›å¼æ€è€ƒ, ä¹Ÿå°±æ˜¯ä»€éº¼éƒ½æ­£å‘æ€ç¶­ä»»ä½•ä½¿ç”¨è€…å¯«çš„äº‹æƒ…,
ç”¨æˆ‘çš„ç¬¬ä¸€äººç¨±ã€ç¤¾ç¾¤åª’é«” po æ–‡çš„å£å»èªªä¸€æ¬¡,
èªªç‚ºä»€éº¼é€™æ˜¯ä¸€ä»¶è¶…å¹¸é‹çš„äº‹, ä¸¦ä¸”ä»¥ã€Œå®Œå…¨æ˜¯ Lucky Vicky å‘€!ã€çµå°¾ã€‚
å¯ä»¥é©åº¦çš„åŠ ä¸Š emojiã€‚"""
    
    messages = [
        {"role": "system", "content": system},
        {"role": "user", "content": "ä»Šå¤©å’–å•¡ç‘äº†"}
    ]
    
    response = client.chat_completion(
        messages=messages,
        model="Qwen/Qwen2.5-7B-Instruct",
        max_tokens=300,
        temperature=0.8
    )
    
    result = response.choices[0].message.content
    print(f"\nğŸ“£ Lucky Vicky è²¼æ–‡:\n{result}")
    
    print("\n" + "="*60)
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•æˆåŠŸ!")
    print("="*60)
    
except Exception as e:
    print(f"\nâŒ é”™è¯¯: {e}")
    print("\nğŸ’¡ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
    print("1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
    print("2. åœ¨ Hugging Face ç½‘ç«™ç¡®è®¤ Token çŠ¶æ€")
    print("3. å°è¯•é‡æ–°ç”Ÿæˆ Token")
    print("4. ç¨åå†è¯• (å¯èƒ½æ˜¯ API æš‚æ—¶ç¹å¿™)")

input("\næŒ‰ Enter é”®é€€å‡º...")

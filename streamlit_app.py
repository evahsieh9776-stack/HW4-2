"""
å“¡ç‘›å¼æ€è€ƒç”Ÿæˆå™¨ - Streamlit Web App
ä½¿ç”¨ Hugging Face Inference API
"""

import streamlit as st
from huggingface_hub import InferenceClient
import os

# ============================================
# é é¢é…ç½®
# ============================================

st.set_page_config(
    page_title="å“¡ç‘›å¼æ€è€ƒç”Ÿæˆå™¨ - Lucky Vicky",
    page_icon="ğŸŒˆ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ============================================
# è‡ªå®šç¾© CSS
# ============================================

st.markdown("""
<style>
    .main-title {
        text-align: center;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        font-size: 3em;
        font-weight: bold;
        margin-bottom: 0.2em;
    }
    
    .subtitle {
        text-align: center;
        color: #666;
        font-size: 1.3em;
        margin-bottom: 2em;
    }
    
    .stTextArea textarea {
        font-size: 1.1em;
    }
    
    .output-box {
        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
        padding: 2em;
        border-radius: 15px;
        margin-top: 1em;
        font-size: 1.1em;
        line-height: 1.8;
    }
    
    .footer {
        text-align: center;
        margin-top: 3em;
        padding: 2em;
        color: #888;
        font-size: 0.9em;
    }
</style>
""", unsafe_allow_html=True)

# ============================================
# Token é…ç½®
# ============================================

@st.cache_resource
def get_hf_client():
    """ç²å– Hugging Face å®¢æˆ¶ç«¯"""
    # å„ªå…ˆå¾ Streamlit secrets è®€å–
    hf_token = None
    
    if hasattr(st, 'secrets') and 'HF_TOKEN' in st.secrets:
        hf_token = st.secrets['HF_TOKEN']
    else:
        # å¾ç’°å¢ƒè®Šæ•¸è®€å–
        hf_token = os.getenv('HF_TOKEN')
        
        # å¾ .env æ–‡ä»¶è®€å–
        if not hf_token:
            try:
                with open('.env', 'r', encoding='utf-8') as f:
                    for line in f:
                        if line.startswith('HF_TOKEN='):
                            hf_token = line.strip().split('=', 1)[1]
                            break
            except FileNotFoundError:
                pass
    
    if hf_token:
        return InferenceClient(token=hf_token), True
    else:
        return None, False

client, token_available = get_hf_client()

# ============================================
# Lucky Vicky ç”Ÿæˆå‡½æ•¸
# ============================================

def generate_lucky_vicky(event, model_choice):
    """ç”Ÿæˆå“¡ç‘›å¼æ€è€ƒè²¼æ–‡"""
    
    if not event or not event.strip():
        return "âŒ è«‹è¼¸å…¥ç™¼ç”Ÿçš„äº‹ä»¶!"
    
    system_prompt = """è«‹ç”¨å°ç£ç¿’æ…£çš„ä¸­æ–‡ä¾†å¯«é€™æ®µ po æ–‡:
è«‹ç”¨å“¡ç‘›å¼æ€è€ƒ, ä¹Ÿå°±æ˜¯ä»€éº¼éƒ½æ­£å‘æ€ç¶­ä»»ä½•ä½¿ç”¨è€…å¯«çš„äº‹æƒ…,
ç”¨æˆ‘çš„ç¬¬ä¸€äººç¨±ã€ç¤¾ç¾¤åª’é«” po æ–‡çš„å£å»èªªä¸€æ¬¡,
èªªç‚ºä»€éº¼é€™æ˜¯ä¸€ä»¶è¶…å¹¸é‹çš„äº‹, ä¸¦ä¸”ä»¥ã€Œå®Œå…¨æ˜¯ Lucky Vicky å‘€!ã€çµå°¾ã€‚
å¯ä»¥é©åº¦çš„åŠ ä¸Š emojiã€‚"""
    
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": event}
    ]
    
    # æ¨¡å‹æ˜ å°„
    model_map = {
        "Meta Llama 3.2-3B (æ¨è–¦)": "meta-llama/Llama-3.2-3B-Instruct",
        "Meta Llama 3.2-1B": "meta-llama/Llama-3.2-1B-Instruct",
        "Microsoft Phi-3": "microsoft/Phi-3-mini-4k-instruct"
    }
    
    model = model_map.get(model_choice, "meta-llama/Llama-3.2-3B-Instruct")
    
    try:
        if not client:
            return "âŒ éŒ¯èª¤: æœªé…ç½® Hugging Face Token\n\nè«‹åœ¨ Streamlit Cloud Secrets ä¸­è¨­ç½® HF_TOKEN"
        
        with st.spinner('ğŸ¤” Lucky Vicky æ­£åœ¨æ€è€ƒä¸­...'):
            response = client.chat_completion(
                messages=messages,
                model=model,
                max_tokens=500,
                temperature=0.8
            )
        
        result = response.choices[0].message.content
        return result
        
    except Exception as e:
        error_msg = str(e)
        
        if "not_supported" in error_msg or "doesn't support" in error_msg:
            return f"âŒ æ¨¡å‹ '{model_choice}' åœ¨å…è²»å¸³æˆ¶ä¸­ä¸å¯ç”¨\n\nğŸ’¡ å»ºè­°:\n1. å˜—è©¦å…¶ä»–æ¨¡å‹\n2. å‡ç´š Hugging Face å¸³æˆ¶"
        elif "401" in error_msg or "Invalid token" in error_msg:
            return "âŒ Token ç„¡æ•ˆæˆ–å·²éæœŸ\n\nè«‹æª¢æŸ¥:\n1. Token æ˜¯å¦æ­£ç¢º\n2. Token æ˜¯å¦æœ‰ 'Read' æ¬Šé™\n3. åœ¨ https://huggingface.co/settings/tokens é‡æ–°ç”Ÿæˆ"
        else:
            return f"âŒ éŒ¯èª¤: {error_msg}\n\nğŸ’¡ å¯èƒ½çš„åŸå› :\n1. ç¶²è·¯é€£æ¥å•é¡Œ\n2. API é€Ÿç‡é™åˆ¶\n3. æ¨¡å‹æš«æ™‚ä¸å¯ç”¨"

# ============================================
# ä¸»ç•Œé¢
# ============================================

# æ¨™é¡Œ
st.markdown('<h1 class="main-title">ğŸŒˆ å“¡ç‘›å¼æ€è€ƒç”Ÿæˆå™¨</h1>', unsafe_allow_html=True)
st.markdown('<p class="subtitle">Lucky Vicky - æŠŠä»»ä½•äº‹æƒ…éƒ½è®Šæˆå¹¸é‹çš„äº‹!</p>', unsafe_allow_html=True)

# Token ç‹€æ…‹æç¤º
if token_available:
    st.success("âœ… Hugging Face Token å·²é…ç½®")
else:
    st.error("âš ï¸ æœªæ‰¾åˆ° Hugging Face Token - è«‹åœ¨ Streamlit Cloud Secrets ä¸­è¨­ç½® HF_TOKEN")

# å´é‚Šæ¬„ - ä½¿ç”¨èªªæ˜
with st.sidebar:
    st.header("ğŸ“– ä½¿ç”¨èªªæ˜")
    
    st.markdown("""
    ### ä»€éº¼æ˜¯å“¡ç‘›å¼æ€è€ƒ?
    
    å“¡ç‘›å¼æ€è€ƒæ˜¯ä¸€ç¨®è¶…ç´šæ­£å‘çš„æ€ç¶­æ–¹å¼,èƒ½æŠŠä»»ä½•çœ‹ä¼¼å€’æ¥£çš„äº‹æƒ…,
    é‡æ–°è©®é‡‹æˆå¹¸é‹çš„äº‹ä»¶!
    
    ### å¦‚ä½•ä½¿ç”¨?
    
    1. åœ¨å³å´è¼¸å…¥æ¡†ä¸­æè¿°ç™¼ç”Ÿçš„äº‹æƒ…
    2. é¸æ“‡ AI æ¨¡å‹ (æ¨è–¦ä½¿ç”¨ Meta Llama 3.2-3B)
    3. é»æ“Šã€Œâœ¨ ç”Ÿæˆ Lucky Vicky è²¼æ–‡ã€
    4. ç­‰å¾… AI ç”Ÿæˆæ­£å‘æ€è€ƒçš„ç¤¾ç¾¤åª’é«”è²¼æ–‡
    
    ### æŠ€è¡“èªªæ˜
    
    - ä½¿ç”¨ Hugging Face Inference API
    - æ”¯æŒå¤šå€‹å…è²» AI æ¨¡å‹
    - å°ˆç‚ºç¹é«”ä¸­æ–‡å„ªåŒ–
    
    ### æ³¨æ„äº‹é …
    
    - å…è²»æ¨¡å‹å¯èƒ½æœ‰é€Ÿç‡é™åˆ¶
    - æŸäº›æ¨¡å‹å¯èƒ½éœ€è¦ä»˜è²»è¨‚é–±
    - å»ºè­°ä½¿ç”¨ Meta Llama æ¨¡å‹ (å…è²»ä¸”æ•ˆæœå¥½)
    """)
    
    st.divider()
    
    st.markdown("### ğŸ’¡ ç¯„ä¾‹äº‹ä»¶")
    examples = [
        "ä»Šå¤©å’–å•¡ç‘åˆ°é›»è…¦ä¸Šäº†!",
        "å‡ºé–€å¿˜è¨˜å¸¶å‚˜,çµæœä¸‹å¤§é›¨",
        "è€ƒè©¦è€ƒå¾—ä¸å¤ªå¥½",
        "ä»Šå¤©é²åˆ°äº†10åˆ†é˜",
        "æ‰‹æ©Ÿæ‰åˆ°æ°´è£¡äº†"
    ]
    
    for example in examples:
        if st.button(example, key=f"example_{example}", use_container_width=True):
            st.session_state.event_input = example

# ä¸»è¦å…§å®¹å€åŸŸ
col1, col2 = st.columns([1, 1])

with col1:
    st.subheader("ğŸ“ ç™¼ç”Ÿäº†ä»€éº¼äº‹?")
    
    # ä½¿ç”¨ session_state ä¾†ä¿å­˜è¼¸å…¥
    if 'event_input' not in st.session_state:
        st.session_state.event_input = ""
    
    event_input = st.text_area(
        label="è¼¸å…¥äº‹ä»¶",
        value=st.session_state.event_input,
        placeholder="ä¾‹å¦‚:ä»Šå¤©å‡ºé–€å°±ä¸‹å¤§é›¨,å¯æ˜¯å¿˜äº†å¸¶å‚˜...",
        height=200,
        label_visibility="collapsed"
    )
    
    st.subheader("ğŸ¤– é¸æ“‡ AI æ¨¡å‹")
    model_choice = st.selectbox(
        label="æ¨¡å‹é¸æ“‡",
        options=[
            "Meta Llama 3.2-3B (æ¨è–¦)",
            "Meta Llama 3.2-1B",
            "Microsoft Phi-3"
        ],
        label_visibility="collapsed"
    )
    
    generate_button = st.button("âœ¨ ç”Ÿæˆ Lucky Vicky è²¼æ–‡", type="primary", use_container_width=True)

with col2:
    st.subheader("ğŸ“£ å“¡ç‘›å¼è²¼æ–‡")
    
    # è¼¸å‡ºå€åŸŸ
    output_container = st.container()
    
    if generate_button:
        if event_input:
            result = generate_lucky_vicky(event_input, model_choice)
            
            with output_container:
                st.markdown(f'<div class="output-box">{result}</div>', unsafe_allow_html=True)
                
                # è¤‡è£½æŒ‰éˆ•
                st.button("ğŸ“‹ è¤‡è£½è²¼æ–‡", key="copy_button")
        else:
            with output_container:
                st.warning("âš ï¸ è«‹å…ˆè¼¸å…¥ç™¼ç”Ÿçš„äº‹ä»¶!")
    else:
        with output_container:
            st.info("ğŸ‘ˆ åœ¨å·¦å´è¼¸å…¥äº‹ä»¶,ç„¶å¾Œé»æ“Šç”ŸæˆæŒ‰éˆ•")

# é è…³
st.markdown("""
<div class="footer">
    <p>ğŸ¤— Powered by Hugging Face Inference API</p>
    <p>ğŸ’¡ æç¤º: å¦‚æœé‡åˆ°å•é¡Œ,è«‹æª¢æŸ¥ Token é…ç½®æˆ–å˜—è©¦å…¶ä»–æ¨¡å‹</p>
    <p>ğŸ“š æ›´å¤šè³‡è¨Šè«‹æŸ¥çœ‹å°ˆæ¡ˆæ–‡æª”</p>
</div>
""", unsafe_allow_html=True)

# ============================================
# æœƒè©±ç‹€æ…‹ç®¡ç†
# ============================================

# åˆå§‹åŒ–æœƒè©±ç‹€æ…‹
if 'generated_count' not in st.session_state:
    st.session_state.generated_count = 0

if generate_button and event_input:
    st.session_state.generated_count += 1
    
# é¡¯ç¤ºçµ±è¨ˆ
with st.sidebar:
    st.divider()
    st.metric("å·²ç”Ÿæˆè²¼æ–‡æ•¸", st.session_state.generated_count)

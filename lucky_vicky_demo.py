"""
å“¡ç‘›å¼æ€è€ƒç”Ÿæˆå™¨ - Gradio Web Demo
ä½¿ç”¨ Hugging Face Inference API
"""

import gradio as gr
from huggingface_hub import InferenceClient
import os

# ============================================
# é…ç½®
# ============================================

# ä» .env æ–‡ä»¶è¯»å– Token
HF_TOKEN = None
try:
    with open('.env', 'r', encoding='utf-8') as f:
        for line in f:
            if line.startswith('HF_TOKEN='):
                HF_TOKEN = line.strip().split('=', 1)[1]
                break
except FileNotFoundError:
    pass

# æˆ–ä»ç¯å¢ƒå˜é‡è¯»å–
if not HF_TOKEN:
    HF_TOKEN = os.getenv('HF_TOKEN')

# åˆ›å»ºå®¢æˆ·ç«¯
if HF_TOKEN:
    client = InferenceClient(token=HF_TOKEN)
    print("âœ… Hugging Face å®¢æˆ·ç«¯å·²åˆ›å»º")
else:
    client = None
    print("âš ï¸  æœªæ‰¾åˆ° Token,æŸäº›åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨")

# ============================================
# Lucky Vicky ç”Ÿæˆå‡½æ•°
# ============================================

def generate_lucky_vicky(event, model_choice="Meta Llama 3.2-3B"):
    """ç”Ÿæˆå“¡ç‘›å¼æ€è€ƒè²¼æ–‡"""
    
    if not event or not event.strip():
        return "âŒ è¯·è¾“å…¥å‘ç”Ÿçš„äº‹ä»¶!"
    
    system_prompt = """è«‹ç”¨å°ç£ç¿’æ…£çš„ä¸­æ–‡ä¾†å¯«é€™æ®µ po æ–‡:
è«‹ç”¨å“¡ç‘›å¼æ€è€ƒ, ä¹Ÿå°±æ˜¯ä»€éº¼éƒ½æ­£å‘æ€ç¶­ä»»ä½•ä½¿ç”¨è€…å¯«çš„äº‹æƒ…,
ç”¨æˆ‘çš„ç¬¬ä¸€äººç¨±ã€ç¤¾ç¾¤åª’é«” po æ–‡çš„å£å»èªªä¸€æ¬¡,
èªªç‚ºä»€éº¼é€™æ˜¯ä¸€ä»¶è¶…å¹¸é‹çš„äº‹, ä¸¦ä¸”ä»¥ã€Œå®Œå…¨æ˜¯ Lucky Vicky å‘€!ã€çµå°¾ã€‚
å¯ä»¥é©åº¦çš„åŠ ä¸Š emojiã€‚"""
    
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": event}
    ]
    
    # æ ¹æ®é€‰æ‹©çš„æ¨¡å‹
    model_map = {
        "Meta Llama 3.2-3B": "meta-llama/Llama-3.2-3B-Instruct",
        "Meta Llama 3.2-1B": "meta-llama/Llama-3.2-1B-Instruct",
        "Microsoft Phi-3": "microsoft/Phi-3-mini-4k-instruct"
    }
    
    model = model_map.get(model_choice, "meta-llama/Llama-3.2-3B-Instruct")
    
    try:
        if not client:
            return "âŒ é”™è¯¯: æœªé…ç½® Hugging Face Token\n\nè¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® HF_TOKEN"
        
        response = client.chat_completion(
            messages=messages,
            model=model,
            max_tokens=500,
            temperature=0.8
        )
        
        result = response.choices[0].message.content
        return result
        
    except Exception as e:
        error_msg = str(e)
        
        if "not_supported" in error_msg or "doesn't support" in error_msg:
            return f"âŒ æ¨¡å‹ '{model_choice}' åœ¨å…è´¹è´¦æˆ·ä¸­ä¸å¯ç”¨\n\nğŸ’¡ å»ºè®®:\n1. å°è¯•å…¶ä»–æ¨¡å‹\n2. å‡çº§ Hugging Face è´¦æˆ·\n3. æˆ–ä½¿ç”¨ Groq API (è§ Notebook)"
        elif "401" in error_msg or "Invalid token" in error_msg:
            return "âŒ Token æ— æ•ˆæˆ–å·²è¿‡æœŸ\n\nè¯·æ£€æŸ¥:\n1. Token æ˜¯å¦æ­£ç¡®\n2. Token æ˜¯å¦æœ‰ 'Read' æƒé™\n3. åœ¨ https://huggingface.co/settings/tokens é‡æ–°ç”Ÿæˆ"
        else:
            return f"âŒ é”™è¯¯: {error_msg}\n\nğŸ’¡ å¯èƒ½çš„åŸå› :\n1. ç½‘ç»œè¿æ¥é—®é¢˜\n2. API é€Ÿç‡é™åˆ¶\n3. æ¨¡å‹æš‚æ—¶ä¸å¯ç”¨"

# ============================================
# ç¤ºä¾‹æ•°æ®
# ============================================

examples = [
    ["ä»Šå¤©å’–å•¡ç‘åˆ°é›»è…¦ä¸Šäº†!", "Meta Llama 3.2-3B"],
    ["å‡ºé–€å¿˜è¨˜å¸¶å‚˜,çµæœä¸‹å¤§é›¨", "Meta Llama 3.2-3B"],
    ["è€ƒè©¦è€ƒå¾—ä¸å¤ªå¥½", "Meta Llama 3.2-1B"],
    ["ä»Šå¤©é²åˆ°äº†10åˆ†é˜", "Meta Llama 3.2-3B"],
    ["æ‰‹æ©Ÿæ‰åˆ°æ°´è£¡äº†", "Microsoft Phi-3"],
]

# ============================================
# Gradio ç•Œé¢
# ============================================

# è‡ªå®šä¹‰ CSS
custom_css = """
.gradio-container {
    font-family: 'Microsoft YaHei', 'Segoe UI', sans-serif;
}

.title {
    text-align: center;
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    font-size: 2.5em;
    font-weight: bold;
    margin-bottom: 0.5em;
}

.subtitle {
    text-align: center;
    color: #666;
    font-size: 1.1em;
    margin-bottom: 2em;
}

.footer {
    text-align: center;
    margin-top: 2em;
    padding: 1em;
    color: #888;
    font-size: 0.9em;
}
"""

# åˆ›å»ºç•Œé¢
with gr.Blocks(
    title="å“¡ç‘›å¼æ€è€ƒç”Ÿæˆå™¨ - Lucky Vicky",
    theme=gr.themes.Soft(
        primary_hue="purple",
        secondary_hue="pink",
    ),
    css=custom_css
) as demo:
    
    # æ ‡é¢˜
    gr.HTML("""
        <div class="title">ğŸŒˆ å“¡ç‘›å¼æ€è€ƒç”Ÿæˆå™¨</div>
        <div class="subtitle">Lucky Vicky - æŠŠä»»ä½•äº‹æƒ…éƒ½è®Šæˆå¹¸é‹çš„äº‹!</div>
    """)
    
    # è¯´æ˜
    with gr.Accordion("ğŸ“– ä½¿ç”¨èªªæ˜", open=False):
        gr.Markdown("""
        ### ä»€éº¼æ˜¯å“¡ç‘›å¼æ€è€ƒ?
        
        å“¡ç‘›å¼æ€è€ƒæ˜¯ä¸€ç¨®è¶…ç´šæ­£å‘çš„æ€ç¶­æ–¹å¼,èƒ½æŠŠä»»ä½•çœ‹ä¼¼å€’æ¥£çš„äº‹æƒ…,
        é‡æ–°è©®é‡‹æˆå¹¸é‹çš„äº‹ä»¶!
        
        ### å¦‚ä½•ä½¿ç”¨?
        
        1. åœ¨ä¸‹æ–¹è¼¸å…¥æ¡†ä¸­æè¿°ç™¼ç”Ÿçš„äº‹æƒ…
        2. é¸æ“‡ AI æ¨¡å‹ (æ¨è–¦ä½¿ç”¨ Meta Llama 3.2-3B)
        3. é»æ“Šã€Œâœ¨ ç”Ÿæˆ Lucky Vicky è²¼æ–‡ã€
        4. ç­‰å¾… AI ç”Ÿæˆæ­£å‘æ€è€ƒçš„ç¤¾ç¾¤åª’é«”è²¼æ–‡
        
        ### æŠ€è¡“èªªæ˜
        
        - ä½¿ç”¨ Hugging Face Inference API
        - æ”¯æŒå¤šå€‹å…è²» AI æ¨¡å‹
        - å°ˆç‚ºç¹é«”ä¸­æ–‡å„ªåŒ–
        
        ### æ³¨æ„äº‹é …
        
        - å…è²»æ¨¡å‹å¯èƒ½æœ‰é€Ÿç‡é™åˆ¶
        - æŸäº›æ¨¡å‹å¯èƒ½éœ€è¦ä»˜è²»è¨‚é–±
        - å»ºè­°ä½¿ç”¨ Meta Llama æ¨¡å‹ (å…è²»ä¸”æ•ˆæœå¥½)
        """)
    
    # ä¸»è¦å†…å®¹
    with gr.Row():
        with gr.Column(scale=2):
            # è¾“å…¥åŒº
            event_input = gr.Textbox(
                label="ğŸ“ ç™¼ç”Ÿäº†ä»€éº¼äº‹?",
                placeholder="ä¾‹å¦‚:ä»Šå¤©å‡ºé–€å°±ä¸‹å¤§é›¨,å¯æ˜¯å¿˜äº†å¸¶å‚˜...",
                lines=4,
                max_lines=10
            )
            
            # æ¨¡å‹é€‰æ‹©
            model_choice = gr.Dropdown(
                choices=[
                    "Meta Llama 3.2-3B",
                    "Meta Llama 3.2-1B",
                    "Microsoft Phi-3"
                ],
                value="Meta Llama 3.2-3B",
                label="ğŸ¤– é¸æ“‡ AI æ¨¡å‹",
                info="æ¨è–¦ä½¿ç”¨ Meta Llama 3.2-3B (å…è²»ä¸”æ•ˆæœå¥½)"
            )
            
            # ç”ŸæˆæŒ‰é’®
            generate_btn = gr.Button(
                "âœ¨ ç”Ÿæˆ Lucky Vicky è²¼æ–‡",
                variant="primary",
                size="lg"
            )
        
        with gr.Column(scale=3):
            # è¾“å‡ºåŒº
            output = gr.Textbox(
                label="ğŸ“£ å“¡ç‘›å¼è²¼æ–‡",
                lines=15,
                max_lines=20,
                placeholder="ç”Ÿæˆçš„ Lucky Vicky è²¼æ–‡æœƒé¡¯ç¤ºåœ¨é€™è£¡..."
            )
    
    # ç¤ºä¾‹
    gr.Examples(
        examples=examples,
        inputs=[event_input, model_choice],
        outputs=output,
        fn=generate_lucky_vicky,
        cache_examples=False,
        label="ğŸ’¡ è©¦è©¦é€™äº›ä¾‹å­"
    )
    
    # ç»‘å®šäº‹ä»¶
    generate_btn.click(
        fn=generate_lucky_vicky,
        inputs=[event_input, model_choice],
        outputs=output
    )
    
    # ä¹Ÿæ”¯æŒæŒ‰ Enter é”®
    event_input.submit(
        fn=generate_lucky_vicky,
        inputs=[event_input, model_choice],
        outputs=output
    )
    
    # é¡µè„š
    gr.HTML("""
        <div class="footer">
            <p>ğŸ¤— Powered by Hugging Face Inference API</p>
            <p>ğŸ’¡ æç¤º: å¦‚æœé‡åˆ°å•é¡Œ,è«‹æª¢æŸ¥ Token é…ç½®æˆ–å˜—è©¦å…¶ä»–æ¨¡å‹</p>
            <p>ğŸ“š æ›´å¤šè³‡è¨Šè«‹æŸ¥çœ‹ <code>å­¸ç¿’ç¸½çµ.md</code></p>
        </div>
    """)

# ============================================
# å¯åŠ¨åº”ç”¨
# ============================================

if __name__ == "__main__":
    print("\n" + "="*60)
    print("ğŸŒˆ å“¡ç‘›å¼æ€è€ƒç”Ÿæˆå™¨ - Lucky Vicky")
    print("="*60)
    
    if HF_TOKEN:
        print(f"âœ… Token å·²é…ç½®: {HF_TOKEN[:10]}...")
    else:
        print("âš ï¸  æœªæ‰¾åˆ° Token")
        print("è«‹åœ¨ .env æ–‡ä»¶ä¸­è¨­ç½® HF_TOKEN")
    
    print("\næ­£åœ¨å•Ÿå‹• Gradio æ‡‰ç”¨...")
    print("æ‡‰ç”¨å°‡åœ¨ç€è¦½å™¨ä¸­è‡ªå‹•æ‰“é–‹")
    print("\næŒ‰ Ctrl+C åœæ­¢æ‡‰ç”¨\n")
    
    # å¯åŠ¨åº”ç”¨
    demo.launch(
        server_name="127.0.0.1",  # æœ¬åœ°è®¿é—®
        server_port=7860,          # ç«¯å£
        share=False,               # ä¸åˆ›å»ºå…¬å¼€é“¾æ¥
        show_error=True,           # æ˜¾ç¤ºé”™è¯¯
        quiet=False                # æ˜¾ç¤ºæ—¥å¿—
    )
